{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "CHR = {\n",
    "    \"chrI\":    1,\n",
    "    \"chrII\":   2,\n",
    "    \"chrIII\":  3,\n",
    "    \"chrIV\":   4,\n",
    "    \"chrV\":    5,\n",
    "    \"chrVI\":   6,\n",
    "    \"chrVII\":  7,\n",
    "    \"chrVIII\": 8,\n",
    "    \"chrIX\":   9,\n",
    "    \"chrX\":    10,\n",
    "    \"chrXI\":   11,\n",
    "    \"chrXII\":  12,\n",
    "    \"chrXIII\": 13,\n",
    "    \"chrXIV\":  14,\n",
    "    \"chrXV\":   15,\n",
    "    \"chrXVI\":  16,\n",
    "    \"chrM\":    1000\n",
    "}\n",
    "\n",
    "\n",
    "class FrequencyAndMappingDataExtracted:\n",
    "    def __init__(self, file_name, save_path):\n",
    "        self.file_name = file_name\n",
    "        self.save_path = save_path\n",
    "        self.columns_name = ['chr', 'strand', 't5', 't3', 'ypd', 'gal', 'type', 'name']\n",
    "\n",
    "    def read_bin_data(self):\n",
    "        f_ori = open(self.file_name, 'r')\n",
    "        count = 0\n",
    "\n",
    "        data_list = []\n",
    "        for line in f_ori.readlines():\n",
    "            if count % 1000 == 0:\n",
    "                print(count)\n",
    "            # if count == 100:\n",
    "            #     break\n",
    "            line_list = line.split()\n",
    "            res = line_list[:6]\n",
    "            temp = \"\"\n",
    "            for idx, ele in enumerate(line_list[6:]):\n",
    "                if idx == len(line_list) - 7:\n",
    "                    res.append(temp.rstrip())\n",
    "                    res.append(ele)\n",
    "                else:\n",
    "                    temp = temp + ele + \" \"\n",
    "            data_list.append(res)\n",
    "            count += 1\n",
    "        f_ori.close()\n",
    "        data = pd.DataFrame(data_list, index=None, columns=self.columns_name)\n",
    "        data.columns = data.loc[0]\n",
    "        data = data[1:]\n",
    "        data.to_csv(self.save_path + os.path.sep + \"data.csv\", index=None)\n",
    "\n",
    "    def get_max_ypd(self, file_name):\n",
    "        data_all = pd.read_csv(file_name)\n",
    "        data_all.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "        genes = list(set(data_all[\"name\"]))\n",
    "        print(len(genes))\n",
    "        result = []\n",
    "        count = 0\n",
    "\n",
    "        for gene in genes:\n",
    "            if count % 500 == 0:\n",
    "                print(\"count: \", count)\n",
    "            max_ypd = data_all[(data_all[\"name\"] == gene) & (data_all[\"type\"] == \"Covering one intact ORF\")]\n",
    "            if max_ypd.empty is False:\n",
    "                max_ypd = max_ypd[max_ypd[\"ypd\"] == max_ypd[\"ypd\"].max()]\n",
    "                result.append(max_ypd.values.tolist()[0])\n",
    "            count += 1\n",
    "\n",
    "        result_unsort = pd.DataFrame(result, columns=self.columns_name)\n",
    "        result_unsort = result_unsort.groupby(\"chr\")\n",
    "\n",
    "        result_sort = pd.DataFrame(index=None, columns=self.columns_name)\n",
    "        for name, group in result_unsort:\n",
    "            group_sort = group.sort_values(by=\"t5\")\n",
    "            result_sort = result_sort.append(group_sort, ignore_index=True)\n",
    "        print(\"result shape:\", result_sort.shape)\n",
    "        result_sort.to_csv(self.save_path + os.path.sep + \"genes002.csv\", index=None)\n",
    "\n",
    "\n",
    "class Mapping:\n",
    "    def __init__(self, file_path_gene, file_name_genes, save_path):\n",
    "        self.file_path_gene = file_path_gene\n",
    "        self.file_name_genes = file_name_genes\n",
    "        self.save_path = save_path\n",
    "        self.length_gene = 1000\n",
    "\n",
    "    def plot_gene(self):\n",
    "        f1 = pd.read_csv(self.file_path_gene)\n",
    "        f2 = pd.read_csv(self.file_name_genes)\n",
    "        f2_part = f2[f2[\"Chr\"] == 1]\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.plot(f1[\"start\"], f1[\"val\"])\n",
    "        # plt.scatter(f1[\"start\"], f1[\"size\"])\n",
    "        # plt.scatter(data[\"start\"], data[\"size\"], s=0.2)\n",
    "        # for start in f2_part[\"t5\"]:\n",
    "        #     plt.axvline(x=start, c=\"r\", linestyle='dotted')\n",
    "        # for end in f2_part[\"t3\"]:\n",
    "        #     plt.axvline(x=end, c=\"b\", linestyle='dashed')\n",
    "        plt.xlim()\n",
    "        plt.ylim()\n",
    "        plt.savefig(self.save_path + os.path.sep + self.file_path_gene[-8:-4] + \".png\", dpi=90, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def get_array_1000_row(self):\n",
    "        genes = pd.read_csv(self.file_name_genes)\n",
    "        count = 0\n",
    "        file_name_gene = \"\"\n",
    "        genes_arr = []\n",
    "        for index, row in genes.iterrows():\n",
    "            if count % 100 == 0:\n",
    "                print(\"count:\", count)\n",
    "            if file_name_gene[:-4] != str(row[\"chr\"]):\n",
    "                file_name_gene = str(row[\"chr\"]) + \".csv\"\n",
    "                gene = pd.read_csv(self.file_path_gene + os.sep + file_name_gene)\n",
    "\n",
    "            start = min(row[\"t3\"], row[\"t5\"])\n",
    "            end   = max(row[\"t3\"], row[\"t5\"]) + 1\n",
    "            if abs(start - end) < self.length_gene or row[\"ypd\"] == 0:\n",
    "                continue\n",
    "            gene_arr = gene.iloc[start: end, [1]]\n",
    "            gene_arr = gene_arr[\"size\"].tolist()\n",
    "            if row[\"t3\"] < row[\"t5\"]:\n",
    "                gene_arr = gene_arr[::-1]\n",
    "            gene_arr = gene_arr[:self.length_gene]\n",
    "            genes_arr.append(row.tolist() + gene_arr)\n",
    "            count += 1\n",
    "        genes_arr_pd = pd.DataFrame(genes_arr)\n",
    "        genes_arr_pd.to_csv(self.save_path + os.path.sep + \"genes_arr_pd.csv\", index=None)\n",
    "\n",
    "    def get_array_1000_row_plus_1(self, t3, t5):\n",
    "        genes = pd.read_csv(self.file_name_genes)\n",
    "        count = 0\n",
    "        file_name_gene = \"\"\n",
    "        genes_arr = []\n",
    "        genes[t5] = genes[\"-1 nucleosome\"]\n",
    "        genes[t3] = genes[\"ORF End\"] + abs(genes[\"-1 nucleosome\"] - genes[\"ORF Start\"])\n",
    "        print(genes.head())\n",
    "\n",
    "        for index, row in genes.iterrows():\n",
    "            if count % 100 == 0:\n",
    "                print(\"count:\", count)\n",
    "            chr_name_mapping = str(CHR[row[\"Chr\"]])\n",
    "            if file_name_gene[:-4] != chr_name_mapping:\n",
    "                file_name_gene = chr_name_mapping + \".csv\"\n",
    "                gene = pd.read_csv(self.file_path_gene + os.sep + file_name_gene)\n",
    "\n",
    "            start = min(row[t3], row[t5])\n",
    "            end   = max(row[t3], row[t5]) + 1\n",
    "            if abs(start - end) < self.length_gene:\n",
    "                continue\n",
    "            gene_arr = gene.iloc[start: end, [1]]\n",
    "            gene_arr = gene_arr[\"size\"].tolist()\n",
    "            if row[t3] < row[t5]:\n",
    "                gene_arr = gene_arr[::-1]\n",
    "            gene_arr = gene_arr[:self.length_gene]\n",
    "            genes_arr.append(row.tolist() + gene_arr)\n",
    "            # print(len(genes_arr), len(genes_arr[0]))\n",
    "            count += 1\n",
    "        genes_arr_pd = pd.DataFrame(genes_arr)\n",
    "        genes_arr_pd.to_csv(self.save_path + os.path.sep + \"genes_arr_pd_plus_1.csv\", index=None)\n",
    "\n",
    "        print(genes_arr_pd.shape)\n",
    "        # print(genes_arr_pd)\n",
    "\n",
    "\n",
    "def run_preprocess():\n",
    "    file_name = r'D:\\code\\Final_project_data_science\\data\\S2_tcd_mTIFAnno.txt'\n",
    "    save_path = r'D:\\code\\Final_project_data_science\\result'\n",
    "    extracted = FrequencyAndMappingDataExtracted(file_name, save_path)\n",
    "\n",
    "    # txt to csv\n",
    "    # prepro.read_bin_data()\n",
    "\n",
    "    data_csv_file_name = r'D:\\code\\Final_project_data_science\\data\\data.csv'\n",
    "    extracted.get_max_ypd(data_csv_file_name)\n",
    "\n",
    "\n",
    "def run_process():\n",
    "    file_path_gene = r'..\\data\\genes_all'\n",
    "    file_name_genes = r'..\\data\\13059_2018_1398_MOESM2_ESM_using.csv'\n",
    "    save_path = r\"..\\result\"\n",
    "    mapping = Mapping(file_path_gene, file_name_genes, save_path)\n",
    "    # process.plot_gene()\n",
    "    mapping.get_array_1000_row_plus_1(t3=\"t3\", t5=\"t5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "class Cluster:\n",
    "    def __init__(self, data, save_path=r\"..\\result\"):\n",
    "        self.data = data\n",
    "        self.length_of_gene = 1000\n",
    "        self.step = 10\n",
    "        self.score = 0\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def plot(self):\n",
    "        plt.figure(figsize=(10, 3))\n",
    "        plt.plot(range(0, self.length_of_gene), self.data.loc[0])\n",
    "        plt.xlabel(\"BP\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def normalization(self):\n",
    "        self.data = self.data.rolling(window=self.step, win_type='gaussian', min_periods=1, axis='columns').mean(std=10)\n",
    "        self.plot()\n",
    "        self.data = self.data.T\n",
    "        my_scaler = preprocessing.StandardScaler().fit(self.data)\n",
    "        self.data = my_scaler.transform(self.data)\n",
    "        self.data = self.data.T\n",
    "        self.data = pd.DataFrame(self.data)\n",
    "\n",
    "        self.plot()\n",
    "\n",
    "        return self.data\n",
    "\n",
    "    def cluster_fit(self, method):\n",
    "        \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        method : KMeans instance\n",
    "            A :class:`~sklearn.cluster.KMeans` instance with the initialization\n",
    "            already set.\n",
    "        \"\"\"\n",
    "        estimator = method.fit_predict(self.data)\n",
    "        score = metrics.silhouette_score(self.data, estimator)\n",
    "        self.score = score\n",
    "        # self.plot()\n",
    "        return estimator\n",
    "\n",
    "    def heat_map(self):\n",
    "        bounds = np.linspace(-1.5, 1.5, 15)\n",
    "        plt.imshow(self.data, norm=colors.BoundaryNorm(boundaries=bounds, ncolors=256), origin=\"lower\", aspect=0.5)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    def get_dbscan_eps(self):\n",
    "        data_np = np.array(self.data)\n",
    "        print(data_np.shape)\n",
    "        # data_np = data_np[0: 100, :20]\n",
    "\n",
    "        def select_MinPts(data, k):\n",
    "            k_dist = []\n",
    "            for i in range(data.shape[0]):\n",
    "                dist = (((data[i] - data) ** 2).sum(axis=1) ** 0.5)\n",
    "                dist.sort()\n",
    "                k_dist.append(dist[k])\n",
    "                print(\"i: \", i, dist[k])\n",
    "            return np.array(k_dist)\n",
    "\n",
    "        k = data_np.shape[1] * 2 - 1\n",
    "        k_dist = select_MinPts(data_np, k)\n",
    "        k_dist.sort()\n",
    "        k_dist_pd = pd.DataFrame({\"k:dist\": k_dist})\n",
    "        k_dist_pd.to_csv(self.save_path + os.path.sep + \"DBSCAN_k_dist.csv\", index=None)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(k_dist.shape[0]), k_dist[::-1])\n",
    "        plt.show()\n",
    "        plt.figure()\n",
    "        plt.scatter(np.arange(k_dist.shape[0]), k_dist[::-1])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "class ResultAnalysis:\n",
    "    def __init__(self, result_data, save_path, method):\n",
    "        self.result_data = result_data\n",
    "        self.save_path = save_path\n",
    "        self.method = method\n",
    "        grouped_genes = self.result_data.groupby(\"predict labels\")\n",
    "        self.mean_of_grouped_genes = grouped_genes.agg(\"mean\")\n",
    "        self.length_gene = 1000\n",
    "\n",
    "        # print(type(grouped_genes.groups))\n",
    "\n",
    "        print(80 * \"*\")\n",
    "        self.groups = {}\n",
    "        for key, item in grouped_genes.groups.items():\n",
    "            print(\"{0} : {1}\".format(key, len(item)))\n",
    "            self.groups[key] = len(item)\n",
    "        print(80 * \"*\")\n",
    "        # print(grouped_genes.groups)\n",
    "\n",
    "    def plot_means(self):\n",
    "        font_size = 16\n",
    "        plt.figure()\n",
    "        for idx, row in self.mean_of_grouped_genes.iterrows():\n",
    "            # row = gaussian_filter1d(row, sigma=5)\n",
    "            plt.plot(range(0, self.length_gene), row, label=str(idx) + \"-->\" + str(self.groups[idx]))\n",
    "            plt.legend()\n",
    "\n",
    "        # plt.title(str(idx))\n",
    "        plt.xlabel(\"BP\", fontsize=font_size)\n",
    "        plt.ylabel(\"Means Normalised Reads\", fontsize=font_size)\n",
    "\n",
    "        plt.savefig(self.save_path + os.path.sep + self.method + \"_0729.png\",\n",
    "                    dpi=180,\n",
    "                    bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def get_kmeans_k(cluster_method=\"DBSCAN\", feature_start=8, file_name=r'..\\data\\genes_arr_pd.csv'):\n",
    "\n",
    "    data_ori = pd.read_csv(file_name)\n",
    "    data = data_ori.iloc[:, feature_start:]\n",
    "\n",
    "    cluster = Cluster(data)\n",
    "    cluster.normalization()\n",
    "    scores = []\n",
    "    for n_clusters in range(2, 12):\n",
    "        print(\"i: \", n_clusters)\n",
    "        cluster_methods = KMeans(init=\"k-means++\", n_clusters=n_clusters, random_state=0)\n",
    "        cluster.cluster_fit(method=cluster_methods[cluster_method])\n",
    "        scores.append(cluster.score)\n",
    "\n",
    "    fontsize = 15\n",
    "    plt.figure()\n",
    "    plt.plot(range(2, 12), scores)\n",
    "    plt.scatter(range(2, 12), scores, c=\"r\")\n",
    "    plt.xlabel(\"K\", fontsize=fontsize)\n",
    "    plt.ylabel(\"Silhouette score\", fontsize=fontsize)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def dbscan_eps_and_min_samples(feature_start=8,\n",
    "                               file_name=r'..\\data\\genes_arr_pd.csv'):\n",
    "    save_path = r\"..\\result\"\n",
    "    data_ori = pd.read_csv(file_name)\n",
    "    data = data_ori.iloc[:, feature_start:]\n",
    "\n",
    "    cluster = Cluster(data=data, save_path=save_path)\n",
    "    cluster.normalization()\n",
    "    # cluster.get_dbscan_eps()\n",
    "\n",
    "    eps_begin = 28\n",
    "    eps_end = 32\n",
    "    mim_samples_begin = 98\n",
    "    min_samples_end = 120\n",
    "    eps = np.arange(eps_begin, eps_end, 1)\n",
    "    min_samples = np.arange(mim_samples_begin, min_samples_end, 2)\n",
    "    results = [[0 for _ in range(5)]]\n",
    "\n",
    "    for i in eps:\n",
    "        for j in min_samples:\n",
    "            print(i, j)\n",
    "            try:\n",
    "                cluster_method = DBSCAN(eps=i, min_samples=j)\n",
    "                predict_labels = cluster.cluster_fit(method=cluster_method)\n",
    "                score = metrics.silhouette_score(data, predict_labels)  # 轮廓系数评价聚类的好坏，值越大越好\n",
    "                raito = len(predict_labels[predict_labels[:] == -1]) / len(predict_labels)  # 计算噪声点个数占总数的比例\n",
    "                n_clusters = len(set(predict_labels)) - (1 if -1 in predict_labels else 0)  # 获取分簇的数目\n",
    "                results.append([i, j, score, raito, n_clusters])\n",
    "                print(\"gird: \", [i, j, score, raito, n_clusters])\n",
    "            except:\n",
    "                continue\n",
    "    results = pd.DataFrame(results)\n",
    "    results.columns = ['eps', 'min_samples', 'score', 'raito', 'n_clusters']\n",
    "\n",
    "    sns.relplot(x=\"eps\", y=\"min_samples\", size='score', data=results, hue=\"n_clusters\")\n",
    "    plt.xlim([23, 35])\n",
    "    plt.ylim([93, 106])\n",
    "    plt.show()\n",
    "    sns.relplot(x=\"eps\", y=\"min_samples\", size='raito', data=results, hue=\"n_clusters\")\n",
    "    plt.xlim([23, 35])\n",
    "    plt.ylim([93, 106])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_cluster(cluster_method=\"k-mean++\", feature_start=8, file_name=r'..\\data\\genes_arr_pd.csv'):\n",
    "    n_digits = 6\n",
    "    save_path = r\"..\\result\"\n",
    "    data_ori = pd.read_csv(file_name)\n",
    "    data = data_ori.iloc[:, feature_start:]\n",
    "\n",
    "    cluster = Cluster(data)\n",
    "    cluster.normalization()\n",
    "    (n_samples, n_features) = data.shape\n",
    "\n",
    "    print(f\"# digits: {n_digits}; # samples: {n_samples}; # features {n_features}\")\n",
    "    print(82 * \"_\")\n",
    "    cluster_methods = {\n",
    "        \"k-means++\": KMeans(init=\"k-means++\", n_clusters=n_digits, random_state=0),\n",
    "        \"DBSCAN\": DBSCAN(eps=30, min_samples=100)\n",
    "    }\n",
    "    predict_labels = cluster.cluster_fit(method=cluster_methods[cluster_method])\n",
    "    print(\"score: \", cluster.score)\n",
    "\n",
    "    method = cluster_method + str(n_digits)\n",
    "\n",
    "    data[\"predict labels\"] = predict_labels\n",
    "    predict_labels_data = data_ori.iloc[:, :feature_start + 1]\n",
    "    predict_labels_data[\"predict labels\"] = predict_labels\n",
    "\n",
    "    # predict_labels_data.to_csv(save_path + os.path.sep + cluster_method + \"_predict_result.csv\", index=None)\n",
    "\n",
    "    print(data.head())\n",
    "\n",
    "    result_analysis = ResultAnalysis(data, save_path, method)\n",
    "    result_analysis.plot_means()\n",
    "\n",
    "    print(82 * \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbscan_eps_and_min_samples(feature_start=8, \n",
    "                           file_name=r'D:\\code\\Final_project_data_science\\data\\genes_arr_pd.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
